"""Database Architect Agent"""
import sys
from pathlib import Path
from typing import Dict, List, Optional
from loguru import logger
import json

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


class DatabaseArchitectAgent:
    """
    Agent responsible for:
    - Designing database schema
    - Creating SQLAlchemy models
    - Generating Alembic migrations
    - Adding indexes and constraints
    """
    
    def __init__(self, qwen_client):
        self.qwen_client = qwen_client
    
    async def design_schema(self, pm_spec: Dict) -> Dict:
        """
        Design database schema from PM specification
        
        Args:
            pm_spec: Product Manager specification with entities and relationships
        
        Returns:
            Dict with models, migrations, and seed data
        """
        logger.info("Starting database schema design...")
        
        prompt = self._build_schema_prompt(pm_spec)
        
        response = await self.qwen_client.generate_code(
            prompt=prompt,
            system_prompt=(
                "You are an expert database architect. Generate production-ready "
                "SQLAlchemy models with proper relationships, constraints, and indexes. "
                "Output ONLY valid JSON."
            ),
            temperature=0.2,
            max_tokens=4000
        )
        
        schema = self._parse_schema(response)
        logger.success(f"Schema designed with {len(schema.get('models', {}))} models")
        return schema
    
    def _build_schema_prompt(self, pm_spec: Dict) -> str:
        """Build the schema design prompt"""
        
        app_name = pm_spec.get('app_name', 'app')
        entities = pm_spec.get('data_entities', [])
        
        entities_str = "\n".join([
            f"- {entity['name']}: {', '.join(entity.get('attributes', []))}"
            for entity in entities
        ])
        
        prompt = f"""
Design a PostgreSQL database schema for: {app_name}

Data Entities:
{entities_str}

Requirements:
1. Create SQLAlchemy ORM models for each entity
2. Use UUID for primary keys
3. Add created_at and updated_at timestamps to all models
4. Include proper relationships (ForeignKey, relationship())
5. Add indexes for frequently queried fields
6. Include constraints (unique, not null)
7. Generate Alembic migration script
8. Provide sample seed data (5 records per table)

Output ONLY valid JSON with this structure:
{{
  "models": {{
    "User": "complete SQLAlchemy model code as string",
    "Task": "complete SQLAlchemy model code as string"
  }},
  "base_imports": "import statements needed",
  "migration": {{
    "upgrade": "Alembic upgrade() function code",
    "downgrade": "Alembic downgrade() function code"
  }},
  "indexes": [
    "CREATE INDEX idx_users_email ON users(email);",
    "CREATE INDEX idx_tasks_status ON tasks(status);"
  ],
  "seed_data": {{
    "users": [
      {{"username": "john_doe", "email": "john@example.com"}},
      {{"username": "jane_smith", "email": "jane@example.com"}}
    ],
    "tasks": [
      {{"title": "Task 1", "status": "pending"}},
      {{"title": "Task 2", "status": "completed"}}
    ]
  }},
  "relationships": [
    "User has many Tasks (one-to-many)",
    "Task belongs to User (many-to-one)"
  ]
}}

Generate complete, production-ready SQLAlchemy models with:
- Proper type hints
- Docstrings
- Validation
- Best practices
"""
        return prompt
    
    def _parse_schema(self, response: str) -> Dict:
        """Parse and validate the schema JSON"""
        response = response.strip()
        
        # Remove markdown code blocks
        if response.startswith("```json"):
            response = response.split("```json")[1].split("```")[0].strip()
        elif response.startswith("```"):
            response = response.split("```")[1].split("```")[0].strip()
        
        schema = json.loads(response)
        
        # Validate required fields
        required_fields = ["models", "base_imports"]
        for field in required_fields:
            if field not in schema:
                logger.warning(f"Missing field: {field}")
        
        return schema
    
    def generate_models_file(self, schema: Dict, output_path: str = None) -> str:
        """
        Generate complete models.py file content
        
        Args:
            schema: Schema dict from design_schema()
            output_path: Optional path to write file
        
        Returns:
            Complete models.py file content as string
        """
        models_code = f"""\"\"\"
Database Models
Auto-generated by AutoDev Database Architect Agent
\"\"\"

{schema.get('base_imports', '')}

from sqlalchemy import Column, String, Integer, Boolean, DateTime, ForeignKey, Text
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship, declarative_base
from datetime import datetime
import uuid

Base = declarative_base()


"""
        
        # Add each model
        for model_name, model_code in schema.get('models', {}).items():
            models_code += f"{model_code}\n\n"
        
        if output_path:
            with open(output_path, 'w') as f:
                f.write(models_code)
            logger.info(f"Models file written to {output_path}")
        
        return models_code
    
    def generate_migration_file(self, schema: Dict, revision_id: str = "001") -> str:
        """
        Generate Alembic migration file content
        
        Args:
            schema: Schema dict from design_schema()
            revision_id: Migration revision number
        
        Returns:
            Complete migration file content
        """
        migration = schema.get('migration', {})
        
        migration_code = f"""\"\"\"Initial schema

Revision ID: {revision_id}
Revises: 
Create Date: {datetime.utcnow().isoformat()}

\"\"\"
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers
revision = '{revision_id}'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
{migration.get('upgrade', '    pass')}


def downgrade():
{migration.get('downgrade', '    pass')}
"""
        return migration_code
    
    def generate_summary(self, schema: Dict) -> str:
        """Generate human-readable summary of schema"""
        
        models = schema.get('models', {})
        relationships = schema.get('relationships', [])
        indexes = schema.get('indexes', [])
        
        summary = f"""
üóÑÔ∏è  DATABASE SCHEMA SUMMARY

**Models:** {len(models)}
{chr(10).join(f"  ‚Ä¢ {name}" for name in models.keys())}

**Relationships:**
{chr(10).join(f"  ‚Ä¢ {rel}" for rel in relationships)}

**Indexes:** {len(indexes)}
{chr(10).join(f"  ‚Ä¢ {idx.split('CREATE INDEX')[1].split(';')[0].strip()}" for idx in indexes if 'CREATE INDEX' in idx)}

**Tables Created:** {len(models)}
**Constraints:** Foreign keys, unique constraints, not null
**Timestamps:** All models include created_at, updated_at
"""
        return summary


async def test_db_architect():
    """Test the Database Architect Agent"""
    from src.utils.qwen_client import get_qwen_client
    from src.agents.product_manager import ProductManagerAgent
    
    # Get PM spec first
    client = get_qwen_client()
    pm_agent = ProductManagerAgent(client)
    
    print("Step 1: Getting PM specification...")
    pm_spec = await pm_agent.analyze_requirements(
        "Build a task management app with users and tasks"
    )
    
    print("\nStep 2: Designing database schema...")
    db_architect = DatabaseArchitectAgent(client)
    schema = await db_architect.design_schema(pm_spec)
    
    print("\n" + "="*60)
    print(db_architect.generate_summary(schema))
    print("="*60)
    
    print("\nüìù Models Generated:")
    for model_name in schema.get('models', {}).keys():
        print(f"  ‚úÖ {model_name}")
    
    print("\nüíæ Full Schema JSON:")
    print(json.dumps(schema, indent=2))


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_db_architect())